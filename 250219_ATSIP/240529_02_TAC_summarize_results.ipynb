{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/sho/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "def get_json(path):\n",
    "    with open(path, 'r') as j:\n",
    "         contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "experiments = {\n",
    "    \"main\": [\"OpenSMILE-OpenSMILE-WavLM_EPR-globaloutput-GRL_esd_fcn\", \"OpenSMILE-OpenSMILE-WavLM_SER-globaloutput-GRL_esd_fcn\", \"relative-attributes_OpenSMILE_esd\", \"msemotts_OpenSMILE_esd\"],\n",
    "    \"features\": [\"OpenSMILE-OpenSMILE-WavLM_EPR-globaloutput-GRL_esd_fcn\", \"WavLM_EPR-globaloutput-GRL_esd_fcn\", \"OpenSMILE_EPR-globaloutput-GRL_esd_fcn\"],\n",
    "    \"methods\": [\"OpenSMILE_EPR-globaloutput-GRL_esd_fcn\", \"OpenSMILE_SER-globaloutput-GRL_esd_fcn\", \"relative-attributes_OpenSMILE_esd\"],\n",
    "    \"GRL\": [\"OpenSMILE-OpenSMILE-WavLM_EPR-globaloutput-GRL_esd_fcn\", \"OpenSMILE-OpenSMILE-WavLM_SER-globaloutput-GRL_esd_fcn\", \"OpenSMILE-OpenSMILE-WavLM_EPR-globaloutput_esd_fcn\", \"OpenSMILE-OpenSMILE-WavLM_SER-globaloutput_esd_fcn\"],\n",
    "    \"SSL\": [\n",
    "        \"OpenSMILE-OpenSMILE-WavLM_EPR-globaloutput-GRL_esd_fcn\", \"WavLM_EPR-globaloutput-GRL_esd_fcn\",\n",
    "        \"OpenSMILE-OpenSMILE-cHubert_EPR-globaloutput-GRL_esd_fcn\", \"cHubert_EPR-globaloutput-GRL_esd_fcn\",\n",
    "        \"OpenSMILE-OpenSMILE-emotion2vec_EPR-globaloutput-GRL_esd_fcn\", \"emotion2vec_EPR-globaloutput-GRL_esd_fcn\",\n",
    "           ],\n",
    "}\n",
    "\n",
    "intensitylabels = [\"L\", \"M\", \"H\"]\n",
    "emos = [\"Angry\", \"Happy\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "mainmodels = list(set([b for a in [experiments[exid] for exid in [\"main\", \"features\", \"methods\"]] for b in a]))\n",
    "mainmodels.sort()\n",
    "mainmodels.remove(\"msemotts_OpenSMILE_esd\")\n",
    "modelnames = list(set([b for a in list(experiments.values()) for b in a]))\n",
    "modelnames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_result(contents, name, sampleid, segment):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=48:\n",
    "            continue\n",
    "        mn, fileid, emotion = a[\"TestID\"].split(\"---\")[-3:]\n",
    "        allocation = {item[0]: item[2] for item in a[\"PresentationOrder\"].split(\", \")}\n",
    "        res = [allocation[key] for key in a[\"Preference\"]]\n",
    "        array = [mn, fileid, emotion, *res]\n",
    "        arrays += [array]\n",
    "\n",
    "    columns = [\"model name\", \"file id\", \"emotion\", \"Lowest Prediction\", \"Highest Prediction\"]\n",
    "    sampledf = pd.DataFrame(np.array(arrays), columns=columns)\n",
    "    samplearrays = []\n",
    "    for mn in modelnames:\n",
    "        for fileid in sampledf[\"file id\"].unique():\n",
    "            params = {\"model name\": [mn], \"file id\": [fileid]}\n",
    "            modeldf = sampledf[get_bool_base_on_conditions(sampledf, params)]\n",
    "            if len(modeldf)>0:\n",
    "                int_array = []\n",
    "                for emotion in emos:\n",
    "                    params = {\"emotion\": [emotion]}\n",
    "                    emotiondf = modeldf[get_bool_base_on_conditions(modeldf, params)]\n",
    "                    a = [(emotiondf[\"Lowest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    b = [(emotiondf[\"Highest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    int_array += [a + b]\n",
    "                array = list(np.array(int_array).reshape(-1)) + list(np.sum(np.array(int_array), axis=0))\n",
    "            else:\n",
    "                array = [None]*30\n",
    "            samplearrays += [[name, sampleid, fileid, mn, *array]]\n",
    "\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\", \"\", cl)]\n",
    "    for emotion in emos + [\"total\"]:\n",
    "        for key in [\"LP\", \"HP\"]:\n",
    "            for label in intensitylabels:\n",
    "                columns += [(f\"{segment}-level control\", emotion, f\"{key}-{label}\")]\n",
    "    result = pd.DataFrame(np.array(samplearrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    return result\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultfiles = glob.glob(f\"./web_service/results/*.json\")\n",
    "resultfiles.sort()\n",
    "resultfiles = resultfiles[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = []\n",
    "results = {key: [] for key in [\"WC\", \"UC\", \"SIM\", \"NAT\"]}\n",
    "for path in resultfiles:\n",
    "    contents, name, sampleid = get_contents(path)\n",
    "    if len(contents)==2:\n",
    "        continue\n",
    "    if len(contents[0][\"TestID\"].split(\"---\"))==3:\n",
    "        testtype = \"WC\"\n",
    "        result = get_control_result(contents, name, sampleid, \"word\")\n",
    "    else:\n",
    "        testtype = contents[0][\"TestID\"].split(\"---\")[0]\n",
    "        if testtype==\"WC\":\n",
    "            result = get_control_result(contents, name, sampleid, \"word\")\n",
    "        elif testtype==\"UC\":\n",
    "            try:\n",
    "                result = get_control_result(contents, name, sampleid, \"utterance\")\n",
    "            except TypeError:\n",
    "                not_found += [path]\n",
    "        elif testtype==\"SIM\":\n",
    "            result = get_mushra_result(contents, name, sampleid, \"SIM\")\n",
    "        elif testtype==\"NAT\":\n",
    "            result = get_mushra_result(contents, name, sampleid, \"NAT\")\n",
    "    results[testtype] += [result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Check Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "segment = \"word\"\n",
    "label = \"WC\" if segment==\"word\" else \"UC\"\n",
    "\n",
    "result = results[label][idx]\n",
    "print(result[(\"basic\", \"\", \"Test Name\")][0])\n",
    "df = result.groupby([(\"basic\",\"\", \"Test ID\"), (\"basic\", \"\", \"model name\")]).sum()[(f\"{segment}-level control\", \"total\")]\n",
    "df.index = [key[1] for key in df.index]\n",
    "df[df.sum(axis=1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "metric = \"NAT\"\n",
    "\n",
    "result = results[metric][idx]\n",
    "print(result[(\"basic\", \"Test Name\")][0])\n",
    "result.groupby([(\"basic\",\"Test Name\"), (\"basic\",\"model name\")]).mean()[metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_gradient(val, min_val=-1, max_val=1, color='red'):\n",
    "    if val < min_val: val = min_val\n",
    "    if val > max_val: val = max_val\n",
    "    normalized_val = (val - min_val) / (max_val - min_val)\n",
    "    \n",
    "    if color == 'red':\n",
    "        red_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb({red_intensity}, 0, 0)'\n",
    "    elif color == 'green':\n",
    "        green_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, {green_intensity}, 0)'\n",
    "    elif color == 'blue':\n",
    "        blue_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, 0, {blue_intensity})'\n",
    "    else:\n",
    "        return 'background-color: none'\n",
    "\n",
    "def apply_color_gradient(df, min_val=0, max_val=1.0):\n",
    "    \"\"\"\n",
    "    df.style.apply(lambda x:apply_color_gradient(x, min_val=0, max_val=100), axis=None)\n",
    "    \"\"\"\n",
    "    styles = df.copy()\n",
    "    for col in styles.columns:\n",
    "        color = 'red' if \"LP\" in col else \"green\"\n",
    "        color = \"blue\" if col==\"mean\" else color\n",
    "        styles[col] = df[col].apply(color_gradient, min_val=min_val, max_val=max_val, color=color)\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "- Emotion Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_list = []\n",
    "\n",
    "models = list(set([l for key in [\"main\", \"features\", \"methods\"] for l in experiments[key]]))\n",
    "models.remove(\"msemotts_OpenSMILE_esd\")\n",
    "models.sort()\n",
    "dfdir = {}\n",
    "for segment in [\"word\", \"utterance\"]:\n",
    "    label = \"WC\" if segment==\"word\" else \"UC\"\n",
    "    df_list = []\n",
    "    for idx in range(len(results[label])):\n",
    "        result = results[label][idx]\n",
    "        if result[(\"basic\", \"\", \"Test Name\")][0] in excluded_list:\n",
    "            continue\n",
    "        df = result.groupby([(\"basic\",\"\", \"Test ID\"), (\"basic\", \"\", \"model name\")]).sum()[(f\"{segment}-level control\", \"total\")]\n",
    "        df.index = [key[1] for key in df.index]\n",
    "        df = df[df.sum(axis=1)>0].loc[models]\n",
    "        df_list += [df]\n",
    "\n",
    "    dfdir[segment] = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        dfdir[segment] = dfdir[segment] + df\n",
    "    total = dfdir[segment].sum(axis=1).values[0]/2\n",
    "    dfdir[segment] = np.round(dfdir[segment]/total*100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdir[\"word\"].style.apply(lambda x:apply_color_gradient(x, min_val=0, max_val=100), axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "- MUSHRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = False\n",
    "excluded_list = []\n",
    "\n",
    "models = list(set([l for key in [\"main\"] for l in experiments[key]]))\n",
    "models.sort()\n",
    "dfdir = {}\n",
    "for metric in [\"NAT\", \"SIM\"]:\n",
    "    add = [\"ground_truth\", \"reconstruct\"] if metric==\"NAT\" else []\n",
    "    df_list = []\n",
    "        \n",
    "    df = pd.concat([results[metric][idx] for idx in range(len(results[metric]))], axis=0)\n",
    "    params = {(\"basic\", \"Test Name\"): list(set(list(df[(\"basic\", \"Test Name\")].unique())) - set(excluded_list))}\n",
    "    df = df[get_bool_base_on_conditions(df, params, True)]\n",
    "    if standardization:\n",
    "        for testid in df[(\"basic\", \"Test ID\")].unique():\n",
    "            a = df[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True)]\n",
    "            col = (metric, \"score\")\n",
    "            df.loc[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True), col]  = (a[col] - a[col].mean()) / a[col].std() \n",
    "    arrays = []\n",
    "    for mn in add+models:\n",
    "        params = {(\"basic\", \"model name\"): [mn]}\n",
    "        d = df[get_bool_base_on_conditions(df, params, True)]\n",
    "        values = d[(metric, \"score\")].values\n",
    "        mean = np.mean(values)\n",
    "        ivl = st.t.interval(alpha=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = (ivl[1]-ivl[0])/2\n",
    "        arrays += [[mean, ivl]]\n",
    "    df = pd.DataFrame(arrays, index=add+models, columns=[\"mean\", \"interval\"])\n",
    "    dfdir[metric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfdir[\"NAT\"]\n",
    "df.style.apply(lambda x:apply_color_gradient(x, min_val=df[\"mean\"].min(), max_val=df[\"mean\"].max()), axis=None, subset=[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
